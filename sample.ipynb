{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "539c2677b182015d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T14:37:48.760233Z",
     "start_time": "2025-05-28T14:37:48.749397Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.file_handler import list_of_files\n",
    "files = list_of_files(\"data/raw/en/\",\".md\")\n",
    "files = [f for f in files if (\"README\" not in f and \"SUMMARY\" not in f)] # Remove README files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d01b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 17:39:29,485 - __main__ - INFO - Successfully parsed headings from data/raw/en/18/78.md\n",
      "2025-05-28 17:39:29,485 - __main__ - INFO - Successfully parsed headings from data/raw/en/18/78.md\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Text': '78\\n\\nयत्र योगेश्वरः कृष्णो यत्र पार्थो धनुर्धरः ।  \\nतत्र श्रीर्विजयो भूतिर्ध्रुवा नीतिर्मतिर्मम ॥७८॥\\n\\nyatra yogeśvaraḥ kṛṣṇo  \\nyatra pārtho dhanur-dharaḥ  \\ntatra śrīr vijayo bhūtir  \\ndhruvā nītir matir mama',\n",
       " 'Translation': '**Wherever there is Krishna, the master of all mystics, and wherever there is Arjuna, the supreme archer, there will also certainly be opulence, victory, extraordinary power, and morality. That is my opinion.**',\n",
       " 'Purport': 'The Bhagavad-gita began with an inquiry of Dhritarashtra\\'s. He was hopeful of the victory of his sons, assisted by great warriors like Bhishma, Drona and Karna. He was hopeful that the victory would be on his side. But after describing the scene on the battlefield, Sanjaya told the King, \"You are thinking of victory, but my opinion is that where Krishna and Arjuna are present, there will be all good fortune.\" He directly confirmed that Dhritarashtra could not expect victory for his side. Victory was certain for the side of Arjuna because Krishna was there. Krishna\\'s acceptance of the post of charioteer for Arjuna was an exhibition of another opulence. Krishna is full of all opulences, and renunciation is one of them. There are many instances of such renunciation, for Krishna is also the master of renunciation.\\n\\nThe fight was actually between Duryodhana and Yudhishthira. Arjuna was fighting on behalf of his elder brother, Yudhishthira. Because Krishna and Arjuna were on the side of Yudhishthira, Yudhishthira\\'s victory was certain. The battle was to decide who would rule the world, and Sanjaya predicted that the power would be transferred to Yudhishthira. It is also predicted here that Yudhishthira, after gaining victory in this battle, would flourish more and more because not only was he righteous and pious but he was also a strict moralist. He never spoke a lie during his life.\\n\\nThere are many less intelligent persons who take Bhagavad-gita to be a discussion of topics between two friends on a battlefield. But such a book cannot be scripture. Some may protest that Krishna incited Arjuna to fight, which is immoral, but the reality of the situation is clearly stated: Bhagavad-gita is the supreme instruction in morality. The supreme instruction of morality is stated in the Ninth Chapter, in the thirty-fourth verse: man-mana bhava mad-bhaktah. One must become a devotee of Krishna, and the essence of all religion is to surrender unto Krishna (sarva-dharman parityajya mam ekam saranam vraja). The instructions of Bhagavad-gita constitute the supreme process of religion and of morality. All other processes may be purifying and may lead to this process, but the last instruction of the Gita is the last word in all morality and religion: surrender unto Krishna. This is the verdict of the Eighteenth Chapter.\\n\\nFrom Bhagavad-gita we can understand that to realize oneself by philosophical speculation and by meditation is one process, but to fully surrender unto Krishna is the highest perfection. This is the essence of the teachings of Bhagavad-gita. The path of regulative principles according to the orders of social life and according to the different courses of religion may be a confidential path of knowledge. But although the rituals of religion are confidential, meditation and cultivation of knowledge are still more confidential. And surrender unto Krishna in devotional service in full Krishna consciousness is the most confidential instruction. That is the essence of the Eighteenth Chapter.\\n\\nAnother feature of Bhagavad-gita is that the actual truth is the Supreme Personality of Godhead, Krishna. The Absolute Truth is realized in three features -- impersonal Brahman, localized Paramatma, and ultimately the Supreme Personality of Godhead, Krishna. Perfect knowledge of the Absolute Truth means perfect knowledge of Krishna. If one understands Krishna, then all the departments of knowledge are part and parcel of that understanding. Krishna is transcendental, for He is always situated in His eternal internal potency. The living entities are manifested of His energy and are divided into two classes, eternally conditioned and eternally liberated. Such living entities are innumerable, and they are considered fundamental parts of Krishna. Material energy is manifested into twenty-four divisions. The creation is effected by eternal time, and it is created and dissolved by external energy. This manifestation of the cosmic world repeatedly becomes visible and invisible.\\n\\nIn Bhagavad-gita five principal subject matters have been discussed: the Supreme Personality of Godhead, material nature, the living entities, eternal time and all kinds of activities. All is dependent on the Supreme Personality of Godhead, Krishna. All conceptions of the Absolute Truth -- impersonal Brahman, localized Paramatma and any other transcendental conception -- exist within the category of understanding the Supreme Personality of Godhead. Although superficially the Supreme Personality of Godhead, the living entity, material nature and time appear to be different, nothing is different from the Supreme. But the Supreme is always different from everything. Lord Caitanya\\'s philosophy is that of \"inconceivable oneness and difference.\" This system of philosophy constitutes perfect knowledge of the Absolute Truth.\\n\\nThe living entity in his original position is pure spirit. He is just like an atomic particle of the Supreme Spirit. Thus Lord Krishna may be compared to the sun, and the living entities to sunshine. Because the living entities are the marginal energy of Krishna, they have a tendency to be in contact either with the material energy or with the spiritual energy. In other words, the living entity is situated between the two energies of the Lord, and because he belongs to the superior energy of the Lord, he has a particle of independence. By proper use of that independence he comes under the direct order of Krishna. Thus he attains his normal condition in the pleasure-giving potency.\\n\\nThus end the Bhaktivedanta Purports to the Eighteenth Chapter of the Srimad Bhagavad-gita in the matter of its Conclusion -- the Perfection of Renunciation.',\n",
       " 'Reference': '18:78'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_ingestion.parsers import read_file\n",
    "from utils.logger import get_logger\n",
    "logger = get_logger(__name__)\n",
    "import re\n",
    "\n",
    "def process_md_adv(path,headings:list[str])->dict:\n",
    "    \"\"\"\n",
    "    Reads a Markdown (.md) file and returns the required headers\n",
    "    :param path: path to the Markdown file\n",
    "    :param headings: list of headings to extract\n",
    "    :return: a dictionary of the extracted headings\n",
    "    \"\"\"\n",
    "    content = read_file(path)\n",
    "\n",
    "    resp = dict((zip(headings, [\"\"] * len(headings))))\n",
    "    resp['Reference'] = \":\".join(path.split('/')[-2:]).replace('.md', '')\n",
    "    if not path.endswith('.md'):\n",
    "        logger.warning('File extension must be .md', path)\n",
    "        return resp\n",
    "    for i in range(len(headings)):\n",
    "        try:\n",
    "            key = headings[i]\n",
    "            pattern = rf\"# {key}(.*?)(?=#|$)\"\n",
    "            match = re.search(pattern, content, re.DOTALL)\n",
    "            match_text = match.group(1) if match else \"\"\n",
    "            resp[key] = match_text.replace(':\\n\\n', ' ').strip()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing file: {path}\")\n",
    "    if not any(resp.values()):\n",
    "        logger.warning(f\"No valid headings found in {path}\")\n",
    "    else:\n",
    "        logger.info(f\"Successfully parsed headings from {path}\")\n",
    "    return resp\n",
    "\n",
    "\n",
    "process_md_adv(\"data/raw/en/18/78.md\",[\"Text\",\"Translation\",\"Purport\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee21ab45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m docs = []\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfiles\u001b[49m:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      4\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for file in files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            content = f.read()\n",
    "            doc = process_md_adv(content, \n",
    "                                [\"Text\", \"Translation\", \"Purport\"])\n",
    "        except Exception as e:\n",
    "            print(file)\n",
    "            break\n",
    "        docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cafe9e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8647a3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/processed/processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(docs)\n",
    "path = \"data/processed/processed_data.csv\"\n",
    "df.to_csv(path, index=False)\n",
    "print(\"Data saved to data/processed/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acf39bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Purport</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>### Setting the Scene\\n\\nAlthough widely publi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>### THE DISCIPLIC SUCCESSION\\n\\nThis _Bhagavad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>### Preface\\n\\nOriginally I wrote _Bhagavad-gī...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>gurum\"&gt;gurum evabhigacchet: [MU 1.2.12] one mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td># Text 3\\n\\nपश्यैतां पाण्डुपुत्राणामाचार्य महत...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Text Translation Purport                                          Reference\n",
       "0                           ### Setting the Scene\\n\\nAlthough widely publi...\n",
       "1                           ### THE DISCIPLIC SUCCESSION\\n\\nThis _Bhagavad...\n",
       "2                           ### Preface\\n\\nOriginally I wrote _Bhagavad-gī...\n",
       "3                           gurum\">gurum evabhigacchet: [MU 1.2.12] one mu...\n",
       "4                           # Text 3\\n\\nपश्यैतां पाण्डुपुत्राणामाचार्य महत..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f1d3518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f91e317c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[32m      4\u001b[39m embeddings = GoogleGenerativeAIEmbeddings(model=\u001b[33m\"\u001b[39m\u001b[33mmodels/embedding-001\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m vectorstore = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:1043\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> FAISS:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     embeddings = \u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__from(\n\u001b[32m   1045\u001b[39m         texts,\n\u001b[32m   1046\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1050\u001b[39m         **kwargs,\n\u001b[32m   1051\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/langchain_google_genai/embeddings.py:208\u001b[39m, in \u001b[36mGoogleGenerativeAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[39m\n\u001b[32m    206\u001b[39m embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m    207\u001b[39m batch_start_index = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mGoogleGenerativeAIEmbeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_prepare_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m titles:\n\u001b[32m    210\u001b[39m         titles_batch = titles[\n\u001b[32m    211\u001b[39m             batch_start_index : batch_start_index + \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[32m    212\u001b[39m         ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/langchain_google_genai/embeddings.py:132\u001b[39m, in \u001b[36mGoogleGenerativeAIEmbeddings._prepare_batches\u001b[39m\u001b[34m(texts, batch_size)\u001b[39m\n\u001b[32m    125\u001b[39m current_text = texts[text_index]\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Number of tokens per a text is conservatively estimated\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# as 2 times number of words, punctuation and whitespace characters.\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# Using `count_tokens` API will make batching too expensive.\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# Utilizing a tokenizer, would add a dependency that would not\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# necessarily be reused by the application using this class.\u001b[39;00m\n\u001b[32m    131\u001b[39m current_text_token_cnt = (\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28mlen\u001b[39m(\u001b[43mGoogleGenerativeAIEmbeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_split_by_punctuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    133\u001b[39m     * \u001b[32m2\u001b[39m\n\u001b[32m    134\u001b[39m )\n\u001b[32m    135\u001b[39m end_of_batch = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_text_token_cnt > _MAX_TOKENS_PER_BATCH:\n\u001b[32m    137\u001b[39m     \u001b[38;5;66;03m# Current text is too big even for a single batch.\u001b[39;00m\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# Such request will fail, but we still make a batch\u001b[39;00m\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# so that the app can get the error from the API.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/langchain_google_genai/embeddings.py:110\u001b[39m, in \u001b[36mGoogleGenerativeAIEmbeddings._split_by_punctuation\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m    108\u001b[39m pattern = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m([\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_by\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m])\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Using re.split to split the text based on the pattern\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [segment \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m segment]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/re/__init__.py:207\u001b[39m, in \u001b[36msplit\u001b[39m\u001b[34m(pattern, string, maxsplit, flags)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msplit\u001b[39m(pattern, string, maxsplit=\u001b[32m0\u001b[39m, flags=\u001b[32m0\u001b[39m):\n\u001b[32m    200\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Split the source string by the occurrences of the pattern,\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03m    returning a list containing the resulting substrings.  If\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[33;03m    capturing parentheses are used in pattern, then the text of all\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    205\u001b[39m \u001b[33;03m    and the remainder of the string is returned as the final element\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03m    of the list.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxsplit\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: expected string or bytes-like object, got 'dict'"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vectorstore = FAISS.from_texts(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_documents(query: str):\n",
    "  \"\"\"\n",
    "  Retrieves relevant documents from the vectorstore for a given query.\n",
    "\n",
    "  Args:\n",
    "    query: The search query.\n",
    "\n",
    "  Returns:\n",
    "    A list of relevant documents.\n",
    "  \"\"\"\n",
    "  return vectorstore.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b1afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "def get_response_from_query(query: str):\n",
    "    \"\"\"\n",
    "    Retrieves relevant documents and generates a response for a given query\n",
    "    using newer LangChain patterns.\n",
    "\n",
    "    Args:\n",
    "      query: The search query.\n",
    "\n",
    "    Returns:\n",
    "      The generated response from the relevant documents.\n",
    "    \"\"\"\n",
    "    # Define a template for the prompt\n",
    "    template = \"\"\"Answer the following question based only on the provided context:\n",
    "    {context}\n",
    "\n",
    "    Question: {input}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Create a stuff document chain\n",
    "    # This chain combines documents into a single prompt and passes it to the model\n",
    "    document_chain = create_stuff_documents_chain(model, prompt)\n",
    "\n",
    "    # Create a retriever from your vectorstore\n",
    "    # This retriever will fetch the most relevant documents based on the query\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    # Create a retrieval chain\n",
    "    # This chain first retrieves documents using the retriever,\n",
    "    # then passes them to the document_chain to generate the response\n",
    "    retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "    # Invoke the retrieval chain with the query\n",
    "    # Use .invoke() instead of .run()\n",
    "    response = retrieval_chain.invoke({\"input\": query})\n",
    "\n",
    "    # The response from the retrieval_chain.invoke will be a dictionary.\n",
    "    # The generated answer is typically in the 'answer' key.\n",
    "    return response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c36d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the Bhagavad-gita, the purpose of life is to deliver mankind from the nescience of material existence. It is also to revive our sanatana occupation, or sanatana-dharma, which is the eternal occupation of the living entity, which is the rendering of service to the Supreme Personality of Godhead.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_from_query(\"What is the purpose of life according to the Bhagavad Gita?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a8cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the provided text, the real principle of religious faith is situated in the mode of pure goodness, and the essence of all religion is to surrender unto Krishna'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_from_query(\"What is real religion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d88cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, here are some ways to control lust:\n",
      "\n",
      "*   **Regulate the senses from the very beginning** and curb lust, the greatest sinful enemy.\n",
      "*   **Learn Krishna consciousness from the very beginning of life.**\n",
      "*   **Transform lust into love for the Supreme** or transform it into Krishna consciousness by desiring everything for Krishna.\n",
      "*   **Steady the mind by deliberate spiritual intelligence (Krishna consciousness)** and conquer lust by spiritual strength.\n",
      "*   **Elevate the mode of passion to the mode of goodness** by the prescribed method of living and acting.\n",
      "*   **Develop Krishna consciousness gradually** to be situated in a transcendental position without being influenced by the material senses and the mind.\n"
     ]
    }
   ],
   "source": [
    "print(get_response_from_query(\"How to control my lust?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1525230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided text:\n",
      "\n",
      "*   Everything that takes place is due to the combination of kshetra and kshetra-jna, the body and the spirit soul. This combination of material nature and the living entity is made possible by the Supreme God Himself.\n",
      "*   The Supreme Personality of Godhead provides the seed, and living entities seem to come out as products of material nature.\n",
      "*   Every living entity, according to his past activities, has a different body, created by this material nature, so that the entity can enjoy or suffer according to his past deeds.\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter your query: \")\n",
    "print(get_response_from_query(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35628077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
